{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 필요 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords             #불용어\n",
    "from urllib.request import urlretrieve\n",
    "import zipfile\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gensim\n",
    "from urllib.request import urlretrieve, urlopen\n",
    "import gzip\n",
    "import zipfile\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파일 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>article_text</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>우리는 많은 시간 인터넷을 이용하고 있지만, 이는 인터넷 회선을 통해 인터넷 서비스...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>우리가 논의를 좀 더 전개하기 전에 먼저 이론적인 것 잠깐만 짚고 넘어가겠습니다. ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>GAN은 콘텐츠 생산 산업에 많은 변화를 가져올 것으로 보인다. 그러나 부정적인 측...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>서양미술 혁신의 첫번째로 르네상스 미술 이야기부터 하겠습니다.\\n한마디로 인간성의 ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>힘은 크기와 방향을 갖는 벡터양으로서 힘의 크기를 나타내는 SI 단위는 뉴턴(N)이...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                       article_text  Unnamed: 2  \\\n",
       "0           1  우리는 많은 시간 인터넷을 이용하고 있지만, 이는 인터넷 회선을 통해 인터넷 서비스...         NaN   \n",
       "1           2  우리가 논의를 좀 더 전개하기 전에 먼저 이론적인 것 잠깐만 짚고 넘어가겠습니다. ...         NaN   \n",
       "2           3  GAN은 콘텐츠 생산 산업에 많은 변화를 가져올 것으로 보인다. 그러나 부정적인 측...         NaN   \n",
       "3           4  서양미술 혁신의 첫번째로 르네상스 미술 이야기부터 하겠습니다.\\n한마디로 인간성의 ...         NaN   \n",
       "4           5  힘은 크기와 방향을 갖는 벡터양으로서 힘의 크기를 나타내는 SI 단위는 뉴턴(N)이...         NaN   \n",
       "\n",
       "   Unnamed: 3  Unnamed: 4  \n",
       "0         NaN         NaN  \n",
       "1         NaN         NaN  \n",
       "2         NaN         NaN  \n",
       "3         NaN         NaN  \n",
       "4         NaN         NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #-*- coding: utf-8 -*- \n",
    "data=pd.read_csv(\"D:/test.csv\", engine='python')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['우리는 많은 시간 인터넷을 이용하고 있지만, 이는 인터넷 회선을 통해 인터넷 서비스를 이용하는 것일 뿐, 내 컴퓨터 안의 파일이 인터넷에 연결되어 있는 것은 아닙니다.',\n",
       " 'HTML로 웹사이트를 만들고 그 내용을 다른 사람들이 볼 수 있도록 하려면 HTML로 만든 웹 문서를 모두 서버 컴퓨터로 옮겨야 합니다.',\n",
       " '서버(server)컴퓨터란 전용선을 통해 인터넷에 직접 연결되어 있는 컴퓨터를 가리키는데, 24시간 인터넷에 연결되어있고 서버 컴퓨터 접속 주소만 알면 누구나 서버 컴퓨터의 내용을 볼 수 있습니다.',\n",
       " '인터넷 회선을 통해 서버 컴퓨터에 접속하는 사용자 컴퓨터를 클라이언트(client)컴퓨터라고 합니다.',\n",
       " '서버 정보를 가져와 보여주는 것은 사용자 컴퓨터 안의 웹 브라우저이기 때문에 좁은 의미로 웹브라우저를 클라이언트라고도 합니다.',\n",
       " '웹 디자이너나 웹 개발자들은 자신이 제작한 최신 웹사이트를 항상 서버 컴퓨터에 업로드해 놓기 때문에 사용자들은 자신의 위치에 상관없이 어디에서나 인터넷에 접속해서 해당 웹사이트의 내용을 볼 수 있습니다.',\n",
       " '개인은 웹 서버를 마련하기 어렵기 때문에 서버의 일부 공간을 매달 혹은 몇 년마다 일정 금액을 내고 사용하는 서비스를 이용합니다.',\n",
       " \"이것을 '서버 호스팅 서비스' 혹은 '웹 호스팅 서비스'라고 하는데, 개인 웹사이트를 운영하는 사람들은 대부분 이런 호스팅 서비스를 이용합니다.\",\n",
       " '호스팅 서비스는 어떤 서버를 이용하느냐에 따라 윈도우 서버 호스팅과 리눅스 서버 호스팅으로 나뉘는데, 윈도우 서버에서는 ASP나 ASAP.NET 프로그래밍 언어를 사용하고, 리눅스 서버에서는 PHP 프로그래밍 언어를 사용하며 좀 더 대중적이고 저렴합니다.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data[['article_text']]\n",
    "data['sentences']=data['article_text'].apply(sent_tokenize)\n",
    "data['sentences'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_text</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>우리는 많은 시간 인터넷을 이용하고 있지만, 이는 인터넷 회선을 통해 인터넷 서비스...</td>\n",
       "      <td>[우리는 많은 시간 인터넷을 이용하고 있지만, 이는 인터넷 회선을 통해 인터넷 서비...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>우리가 논의를 좀 더 전개하기 전에 먼저 이론적인 것 잠깐만 짚고 넘어가겠습니다. ...</td>\n",
       "      <td>[우리가 논의를 좀 더 전개하기 전에 먼저 이론적인 것 잠깐만 짚고 넘어가겠습니다....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GAN은 콘텐츠 생산 산업에 많은 변화를 가져올 것으로 보인다. 그러나 부정적인 측...</td>\n",
       "      <td>[GAN은 콘텐츠 생산 산업에 많은 변화를 가져올 것으로 보인다., 그러나 부정적인...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>서양미술 혁신의 첫번째로 르네상스 미술 이야기부터 하겠습니다.\\n한마디로 인간성의 ...</td>\n",
       "      <td>[서양미술 혁신의 첫번째로 르네상스 미술 이야기부터 하겠습니다., 한마디로 인간성의...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>힘은 크기와 방향을 갖는 벡터양으로서 힘의 크기를 나타내는 SI 단위는 뉴턴(N)이...</td>\n",
       "      <td>[힘은 크기와 방향을 갖는 벡터양으로서 힘의 크기를 나타내는 SI 단위는 뉴턴(N)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        article_text  \\\n",
       "0  우리는 많은 시간 인터넷을 이용하고 있지만, 이는 인터넷 회선을 통해 인터넷 서비스...   \n",
       "1  우리가 논의를 좀 더 전개하기 전에 먼저 이론적인 것 잠깐만 짚고 넘어가겠습니다. ...   \n",
       "2  GAN은 콘텐츠 생산 산업에 많은 변화를 가져올 것으로 보인다. 그러나 부정적인 측...   \n",
       "3  서양미술 혁신의 첫번째로 르네상스 미술 이야기부터 하겠습니다.\\n한마디로 인간성의 ...   \n",
       "4  힘은 크기와 방향을 갖는 벡터양으로서 힘의 크기를 나타내는 SI 단위는 뉴턴(N)이...   \n",
       "\n",
       "                                           sentences  \n",
       "0  [우리는 많은 시간 인터넷을 이용하고 있지만, 이는 인터넷 회선을 통해 인터넷 서비...  \n",
       "1  [우리가 논의를 좀 더 전개하기 전에 먼저 이론적인 것 잠깐만 짚고 넘어가겠습니다....  \n",
       "2  [GAN은 콘텐츠 생산 산업에 많은 변화를 가져올 것으로 보인다., 그러나 부정적인...  \n",
       "3  [서양미술 혁신의 첫번째로 르네상스 미술 이야기부터 하겠습니다., 한마디로 인간성의...  \n",
       "4  [힘은 크기와 방향을 갖는 벡터양으로서 힘의 크기를 나타내는 SI 단위는 뉴턴(N)...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec 파일 가져오기 (더 좋은 파일 있으면 대체하기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kovec=Word2Vec.load(\"D:\\ko.bin\")\n",
    "#kovec=gensim.models.KeyedVectors.load_word2vec_format('D:\\ko.bin',binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Word2Vec(data,sg=1,size=100,window=3,min_count=3,workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 불용어 추가 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence=[re.sub(r'[^가-힣\\s]','',word) for word in sentence]\n",
    "    return [word for word in sentence if word not in stop_words and word]\n",
    "\n",
    "def preprocess_sentences(sentences):\n",
    "    return [preprocess_sentence(sentence) for sentence in sentences]\n",
    "#a-zA-Z, 즉 영어는 포함 안되게 했음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        article_text  \\\n",
      "0  우리는 많은 시간 인터넷을 이용하고 있지만, 이는 인터넷 회선을 통해 인터넷 서비스...   \n",
      "1  우리가 논의를 좀 더 전개하기 전에 먼저 이론적인 것 잠깐만 짚고 넘어가겠습니다. ...   \n",
      "2  GAN은 콘텐츠 생산 산업에 많은 변화를 가져올 것으로 보인다. 그러나 부정적인 측...   \n",
      "3  서양미술 혁신의 첫번째로 르네상스 미술 이야기부터 하겠습니다.\\n한마디로 인간성의 ...   \n",
      "4  힘은 크기와 방향을 갖는 벡터양으로서 힘의 크기를 나타내는 SI 단위는 뉴턴(N)이...   \n",
      "\n",
      "                                           sentences  \\\n",
      "0  [우리는 많은 시간 인터넷을 이용하고 있지만, 이는 인터넷 회선을 통해 인터넷 서비...   \n",
      "1  [우리가 논의를 좀 더 전개하기 전에 먼저 이론적인 것 잠깐만 짚고 넘어가겠습니다....   \n",
      "2  [GAN은 콘텐츠 생산 산업에 많은 변화를 가져올 것으로 보인다., 그러나 부정적인...   \n",
      "3  [서양미술 혁신의 첫번째로 르네상스 미술 이야기부터 하겠습니다., 한마디로 인간성의...   \n",
      "4  [힘은 크기와 방향을 갖는 벡터양으로서 힘의 크기를 나타내는 SI 단위는 뉴턴(N)...   \n",
      "\n",
      "                                      tokenized_data  \n",
      "0  [[우리, 많다, 시간, 인터넷, 을, 이용, 하고, 있다, 이다, 인터넷, 회선,...  \n",
      "1  [[우리, 논의, 더, 전개, 전, 먼저, 이론, 적, 인, 것, 잠깐, 만, 짚다...  \n",
      "2  [[콘텐츠, 생산, 산업, 많다, 변화, 가져오다, 것, 보이다], [그러나, 부정...  \n",
      "3  [[서양미술, 혁신, 첫, 번째, 로, 르네상스, 미술, 이야기, 부터], [한마디...  \n",
      "4  [[힘, 크기, 방향, 을, 갖다, 벡터, 양, 으로서, 힘, 크기, 나타내다, 단...  \n"
     ]
    }
   ],
   "source": [
    "## 형태소 단위로 Tokenize\n",
    "from konlpy.tag import Okt  \n",
    "okt=Okt()\n",
    "\n",
    "def tokenization(sentences):\n",
    "    temp=[]\n",
    "    for sentence in sentences:\n",
    "        temp_X=okt.morphs(sentence,stem=True)\n",
    "        temp_X=[word for word in temp_X]\n",
    "        temp.append(temp_X)\n",
    "    return temp\n",
    "\n",
    "\n",
    "data['tokenized_data']=data['sentences'].apply(tokenization)\n",
    "    \n",
    "data['tokenized_data']=data['tokenized_data'].apply(preprocess_sentences)\n",
    "    \n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim=200\n",
    "zero_vector=np.zeros(embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문장별 벡터값 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sentence_vector(sentence):\n",
    "    if len(sentence) != 0:\n",
    "        sum=0\n",
    "        for word in sentence:\n",
    "            try: \n",
    "                sum+=kovec.wv[word]\n",
    "            except Exception:\n",
    "                sum+=zero_vector\n",
    "        return sum/len(sentence)\n",
    "    else:\n",
    "        return zero_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_to_vectors(sentences):\n",
    "    return [calculate_sentence_vector(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentenceEmbedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[-0.19131963, 0.002412068, -0.478244, 0.49261...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[-0.05495586, -0.2989531, 0.074204944, 0.0287...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[0.23017685, -0.068566605, 0.19649297, 0.6754...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[-0.7269085413879819, -0.9547493942081928, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[0.14874788, 0.07012593, -0.24334846, -0.4889...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   SentenceEmbedding\n",
       "0  [[-0.19131963, 0.002412068, -0.478244, 0.49261...\n",
       "1  [[-0.05495586, -0.2989531, 0.074204944, 0.0287...\n",
       "2  [[0.23017685, -0.068566605, 0.19649297, 0.6754...\n",
       "3  [[-0.7269085413879819, -0.9547493942081928, 0....\n",
       "4  [[0.14874788, 0.07012593, -0.24334846, -0.4889..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['SentenceEmbedding']=data['tokenized_data'].apply(sentences_to_vectors)\n",
    "data[['SentenceEmbedding']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문장별 유사도 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_matrix(sentence_embedding):\n",
    "    sim_mat=np.zeros([len(sentence_embedding),len(sentence_embedding)])\n",
    "    for i in range(len(sentence_embedding)):\n",
    "        for j in range(len(sentence_embedding)):\n",
    "            sim_mat[i][j]=cosine_similarity(sentence_embedding[i].reshape(1,embedding_dim),\n",
    "                                           sentence_embedding[j].reshape(1,embedding_dim))[0,0]\n",
    "    return sim_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [[1.0000001192092896, 0.6782692074775696, 0.88...\n",
       "1    [[1.0, 0.5473900547815026, 0.28144019842147827...\n",
       "2    [[1.0000001192092896, 0.2837713360786438, 0.33...\n",
       "3    [[1.0, 0.3556040231558631, 0.20608101207169816...\n",
       "4    [[1.0000001192092896, 0.813560962677002, 0.714...\n",
       "Name: SimMatrix, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['SimMatrix']=data['SentenceEmbedding'].apply(similarity_matrix)\n",
    "data['SimMatrix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def draw_graphs(sim_matrix):\n",
    "    nx_graph=nx.from_numpy_array(sim_matrix)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    pos=nx.spring_layout(nx_graph)\n",
    "    nx.draw(nx_graph,with_labels=True,font_weight='bold')\n",
    "    nx.draw_networkx_edge_labels(nx_graph,pos,font_color='red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "draw_graphs(data['SimMatrix'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 점수 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score(sim_matrix):\n",
    "    nx_graph=nx.from_numpy_array(sim_matrix)\n",
    "    scores=nx.pagerank_numpy(nx_graph)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SimMatrix</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[1.0000001192092896, 0.6782692074775696, 0.88...</td>\n",
       "      <td>{0: 0.11228407622699133, 1: 0.1038480801169705...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[1.0, 0.5473900547815026, 0.28144019842147827...</td>\n",
       "      <td>{0: 0.05687100044764587, 1: 0.0625569719751471...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[1.0000001192092896, 0.2837713360786438, 0.33...</td>\n",
       "      <td>{0: 0.04406322355924085, 1: 0.0316508886299722...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[1.0, 0.3556040231558631, 0.20608101207169816...</td>\n",
       "      <td>{0: 0.08598122421458233, 1: 0.0932427771800998...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[1.0000001192092896, 0.813560962677002, 0.714...</td>\n",
       "      <td>{0: 0.06560539019924444, 1: 0.0679637572320210...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           SimMatrix  \\\n",
       "0  [[1.0000001192092896, 0.6782692074775696, 0.88...   \n",
       "1  [[1.0, 0.5473900547815026, 0.28144019842147827...   \n",
       "2  [[1.0000001192092896, 0.2837713360786438, 0.33...   \n",
       "3  [[1.0, 0.3556040231558631, 0.20608101207169816...   \n",
       "4  [[1.0000001192092896, 0.813560962677002, 0.714...   \n",
       "\n",
       "                                               score  \n",
       "0  {0: 0.11228407622699133, 1: 0.1038480801169705...  \n",
       "1  {0: 0.05687100044764587, 1: 0.0625569719751471...  \n",
       "2  {0: 0.04406322355924085, 1: 0.0316508886299722...  \n",
       "3  {0: 0.08598122421458233, 1: 0.0932427771800998...  \n",
       "4  {0: 0.06560539019924444, 1: 0.0679637572320210...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['score']=data['SimMatrix'].apply(calculate_score)\n",
    "data[['SimMatrix','score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.11228407622699133,\n",
       " 1: 0.10384808011697051,\n",
       " 2: 0.11604758798046202,\n",
       " 3: 0.11522323151704224,\n",
       " 4: 0.10945307875867902,\n",
       " 5: 0.11493492253322914,\n",
       " 6: 0.10619924547368009,\n",
       " 7: 0.11320730828755055,\n",
       " 8: 0.1088024691053952}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['score'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranked_sentences(sentences,scores,n=7):\n",
    "    top_scores=sorted(((scores[i],s)\n",
    "                      for i,s in enumerate(sentences)),\n",
    "                     reverse=True)\n",
    "    top_n_sentences=[sentence for score,sentence in top_scores[:n]]\n",
    "    return \" \".join(top_n_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### 요약 결과값 산출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['summary'] = data.apply(lambda x:\n",
    "                            ranked_sentences(x.sentences, x.score),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 번 문서\n",
      "원문 :  우리는 많은 시간 인터넷을 이용하고 있지만, 이는 인터넷 회선을 통해 인터넷 서비스를 이용하는 것일 뿐, 내 컴퓨터 안의 파일이 인터넷에 연결되어 있는 것은 아닙니다. HTML로 웹사이트를 만들고 그 내용을 다른 사람들이 볼 수 있도록 하려면 HTML로 만든 웹 문서를 모두 서버 컴퓨터로 옮겨야 합니다. 서버(server)컴퓨터란 전용선을 통해 인터넷에 직접 연결되어 있는 컴퓨터를 가리키는데, 24시간 인터넷에 연결되어있고 서버 컴퓨터 접속 주소만 알면 누구나 서버 컴퓨터의 내용을 볼 수 있습니다. \n",
      "인터넷 회선을 통해 서버 컴퓨터에 접속하는 사용자 컴퓨터를 클라이언트(client)컴퓨터라고 합니다. 서버 정보를 가져와 보여주는 것은 사용자 컴퓨터 안의 웹 브라우저이기 때문에 좁은 의미로 웹브라우저를 클라이언트라고도 합니다. \n",
      "웹 디자이너나 웹 개발자들은 자신이 제작한 최신 웹사이트를 항상 서버 컴퓨터에 업로드해 놓기 때문에 사용자들은 자신의 위치에 상관없이 어디에서나 인터넷에 접속해서 해당 웹사이트의 내용을 볼 수 있습니다. \n",
      "개인은 웹 서버를 마련하기 어렵기 때문에 서버의 일부 공간을 매달 혹은 몇 년마다 일정 금액을 내고 사용하는 서비스를 이용합니다. 이것을 '서버 호스팅 서비스' 혹은 '웹 호스팅 서비스'라고 하는데, 개인 웹사이트를 운영하는 사람들은 대부분 이런 호스팅 서비스를 이용합니다.\n",
      "호스팅 서비스는 어떤 서버를 이용하느냐에 따라 윈도우 서버 호스팅과 리눅스 서버 호스팅으로 나뉘는데, 윈도우 서버에서는 ASP나 ASAP.NET 프로그래밍 언어를 사용하고, 리눅스 서버에서는 PHP 프로그래밍 언어를 사용하며 좀 더 대중적이고 저렴합니다. \n",
      " \n",
      "요약 :  서버(server)컴퓨터란 전용선을 통해 인터넷에 직접 연결되어 있는 컴퓨터를 가리키는데, 24시간 인터넷에 연결되어있고 서버 컴퓨터 접속 주소만 알면 누구나 서버 컴퓨터의 내용을 볼 수 있습니다. 인터넷 회선을 통해 서버 컴퓨터에 접속하는 사용자 컴퓨터를 클라이언트(client)컴퓨터라고 합니다. 웹 디자이너나 웹 개발자들은 자신이 제작한 최신 웹사이트를 항상 서버 컴퓨터에 업로드해 놓기 때문에 사용자들은 자신의 위치에 상관없이 어디에서나 인터넷에 접속해서 해당 웹사이트의 내용을 볼 수 있습니다. 이것을 '서버 호스팅 서비스' 혹은 '웹 호스팅 서비스'라고 하는데, 개인 웹사이트를 운영하는 사람들은 대부분 이런 호스팅 서비스를 이용합니다. 우리는 많은 시간 인터넷을 이용하고 있지만, 이는 인터넷 회선을 통해 인터넷 서비스를 이용하는 것일 뿐, 내 컴퓨터 안의 파일이 인터넷에 연결되어 있는 것은 아닙니다. 서버 정보를 가져와 보여주는 것은 사용자 컴퓨터 안의 웹 브라우저이기 때문에 좁은 의미로 웹브라우저를 클라이언트라고도 합니다. 호스팅 서비스는 어떤 서버를 이용하느냐에 따라 윈도우 서버 호스팅과 리눅스 서버 호스팅으로 나뉘는데, 윈도우 서버에서는 ASP나 ASAP.NET 프로그래밍 언어를 사용하고, 리눅스 서버에서는 PHP 프로그래밍 언어를 사용하며 좀 더 대중적이고 저렴합니다.\n",
      "\n",
      "2 번 문서\n",
      "원문 :  우리가 논의를 좀 더 전개하기 전에 먼저 이론적인 것 잠깐만 짚고 넘어가겠습니다. 새로운 지식을 탐색하는 방법, 그러니까 우리가 연구 방법론이라고 하죠.\n",
      "연구방법에는 크게 보면 두 가지가 있습니다. 그 첫 번째는 연역적인 접근 방법이 있고요. 또 하나는 귀납적인 접근 방법이 있습니다.\n",
      "연역이라는 것은 우리가 이미 알고 있는 일반적인 지식이나 법칙, 원리로부터 어떤 논리적인 규칙,\n",
      "즉 다시 말해서 합리적인 추론에 따라 필연적인 결론을 이끌어내는 것이 바로 연역이라고 볼 수 있겠어요.\n",
      "지금의 문제를 풀기 위해서 우리가 이미 알고 있는 지식을 중심으로 해서\n",
      "‘뭐는 어떻고 뭐는 어떻기 때문에 이건 이럴 거야.’라고 문제해결을 한다고 하면, 이건 연역적인 접근이라고 볼 수 있겠어요.\n",
      "또 한 가지 접근법은 귀납적인 접근법인데요. 귀납적인 접근법은 어떤 개별 사례에 대한 관찰을 통해서 일반적인 결론을 이끌어내는 접근 방법이라고 보실 수 있겠어요.\n",
      "귀납은 과거의 사례라든지 축적된 데이터를 분석해서 그 안에서 보인 어떤 공통적인 패턴 같은 걸 찾아서 지금의 문제를 해결하는 그런 접근법이라고 말을 할 수가 있겠습니다.\n",
      "여러분, 어떠세요? 빅데이터는 연역에 해당될까요? 아니면 귀납적인 접근에 해당될까요?\n",
      "그렇습니다. 빅데이터는 아주 전형적으로 귀납적인 지식 탐색 접근법에 해당한다고 일단 보시면 되겠습니다. 크게 보면 이 두 가지가 있었던 겁니다.\n",
      "이렇게 원래 연역하고 귀납이라는 걸 통해서 우리가 지식을 찾고, 처리하고, 문제를 해결하고 원래 이렇게 하는 것인데요.\n",
      "조금 전에 말씀드린 대로 빅데이터는 이 귀납적인 지식 추출 방법론이라고 했습니다.\n",
      "\n",
      " \n",
      "요약 :  귀납은 과거의 사례라든지 축적된 데이터를 분석해서 그 안에서 보인 어떤 공통적인 패턴 같은 걸 찾아서 지금의 문제를 해결하는 그런 접근법이라고 말을 할 수가 있겠습니다. 귀납적인 접근법은 어떤 개별 사례에 대한 관찰을 통해서 일반적인 결론을 이끌어내는 접근 방법이라고 보실 수 있겠어요. 연역이라는 것은 우리가 이미 알고 있는 일반적인 지식이나 법칙, 원리로부터 어떤 논리적인 규칙,\n",
      "즉 다시 말해서 합리적인 추론에 따라 필연적인 결론을 이끌어내는 것이 바로 연역이라고 볼 수 있겠어요. 빅데이터는 아주 전형적으로 귀납적인 지식 탐색 접근법에 해당한다고 일단 보시면 되겠습니다. 또 하나는 귀납적인 접근 방법이 있습니다. 조금 전에 말씀드린 대로 빅데이터는 이 귀납적인 지식 추출 방법론이라고 했습니다. 새로운 지식을 탐색하는 방법, 그러니까 우리가 연구 방법론이라고 하죠.\n",
      "\n",
      "3 번 문서\n",
      "원문 :  GAN은 콘텐츠 생산 산업에 많은 변화를 가져올 것으로 보인다. 그러나 부정적인 측면도 있다. 도용과 정치 악용이 이에 해당한다. 참고로 이러한 악용을 딥페이크(DeepFake)라고 부른다.\n",
      "딥페이크는 AI 알고리즘 중 하나인 딥러닝(Deep Learning)과 가짜를 뜻하는 페이크(Fake)와의 합성어이다.\n",
      "딥페이크로 인한 도용 문제는 심각하다.  딥트레이스는 2018년 한해 7964개의 딥페이크 영상을 발견했다. 그리고 2019년 1월부터 9월까지는 1만 4678개를 발견했다. 1년 사이 2배 넘게 딥페이크 영상물이 생겨난 셈이다. 그중 96%가량이 포르노 영상이다.\n",
      "참고로 지난 4월 N번 방에서 딥페이크를 악용한 포르노 사진이 유포되기도 했다. 이에 따라, 국내에서는 딥페이크 포르노 제작 및 배포를 처벌하는 법이 25일부터 시행된다. 5년 이하의 징역이 처해지게 되는데, 특히 영리 목적으로 제작하거나 배포하면 7년 이하의 징역이 처해진다.\n",
      "도용뿐만 아니라 정치적 악용 또한 문제다. 2018년 4월 미국 콘텐츠 제작사인 버즈피드(BuzzFeed)는 이러한 위험성을 경고하고자 딥페이크 영상을 유튜브에 올린 바 있다. 해당 영상에는 미국 전 대통령 버락 오바마가 집무실 배경으로 도널드 트럼프 정권을 비판하고 있는데, 이는 진짜 영상이 아닌 딥페이크 영상이었다.\n",
      "이러한 일은 실제로 발생하고 있다. 이탈리아 전 총리 ‘마테오 렌치(Matteo Renzi)’가 다른 사회인을 모욕하는 딥페이크 영상이 올라와 사회적 혼란을 야기했다. 2018년 멕시코에서는 대통령 후보를 깎아내리기 위한 딥페이크 영상이 올라오기도 했다.\n",
      "이처럼 AI 생성 모델은 딥페이크라는 부작용이 있다. 이에 대응하는 기술 연구도 한창이다. 페이스북, 마이크로소프트, 구글 등이 앞장서 이를 식별하는 연구를 진행하고 있다.\n",
      "GAN 알고리즘에서의 두 요인 경쟁이 실제 사회로까지 확장된 셈이다. GAN 알고리즘은 생성자를 위해 식별자라는 요인을 넣었는데, 딥페이크 대응을 위해서는 식별자를 강화하는 연구도 필요하다.\n",
      " \n",
      "요약 :  해당 영상에는 미국 전 대통령 버락 오바마가 집무실 배경으로 도널드 트럼프 정권을 비판하고 있는데, 이는 진짜 영상이 아닌 딥페이크 영상이었다. 딥트레이스는 2018년 한해 7964개의 딥페이크 영상을 발견했다. 2018년 4월 미국 콘텐츠 제작사인 버즈피드(BuzzFeed)는 이러한 위험성을 경고하고자 딥페이크 영상을 유튜브에 올린 바 있다. GAN 알고리즘은 생성자를 위해 식별자라는 요인을 넣었는데, 딥페이크 대응을 위해서는 식별자를 강화하는 연구도 필요하다. GAN 알고리즘에서의 두 요인 경쟁이 실제 사회로까지 확장된 셈이다. 이에 따라, 국내에서는 딥페이크 포르노 제작 및 배포를 처벌하는 법이 25일부터 시행된다. 페이스북, 마이크로소프트, 구글 등이 앞장서 이를 식별하는 연구를 진행하고 있다.\n",
      "\n",
      "4 번 문서\n",
      "원문 :  서양미술 혁신의 첫번째로 르네상스 미술 이야기부터 하겠습니다.\n",
      "한마디로 인간성의 부활, 인문주의의 시작이었다고 말씀 드릴 수 있습니다.\n",
      "단순한 복고 정신의 추구 뿐만 아니라 인간성의 부활이라는 큰 의미가 들어있습니다.\n",
      "신 중심의 사회에서 인간 중심의 사회로 나가고자 하는 바람이 있는 것입니다.\n",
      "르네상스 미술에서 다음과 같은 획기적인 혁신이 있었습니다.\n",
      "유화의 사용으로 다양하고 풍부한 색채로 화가들은 색조의 단계적 변화를 무리 없이 표현할 수 있게 되었습니다.\n",
      "사실상 서양 미술사에서 가장 획기적인 사건으로 평면위에 공간감과 거리감을 표현하는 방법인 원근법의 탄생 입니다.\n",
      "이 방법은 이후 500년 동안 서구 회화의 기초가 되지요.\n",
      "미켈란젤로, 레오나르도 다빈치 와 함께 르네상스 시대 3대 거장 중 하나로 언급되는 라파엘로는 〈황금방울새와 성모〉를 그렸습니다.\n",
      "어떻습니까? 화면의 안정감이 느껴 지시지요.\n",
      "삼각구도법을 활용하고, 이 작품에서 성모의 머리끝을 꼭짓점으로 한 삼각형 모양의 구도로 인물들을 배치했습니다.\n",
      "르네상스 미술의 특징인 하모니엔 발란스를 잘 이룬 작품입니다.\n",
      " \n",
      "요약 :  사실상 서양 미술사에서 가장 획기적인 사건으로 평면위에 공간감과 거리감을 표현하는 방법인 원근법의 탄생 입니다. 한마디로 인간성의 부활, 인문주의의 시작이었다고 말씀 드릴 수 있습니다. 르네상스 미술에서 다음과 같은 획기적인 혁신이 있었습니다. 유화의 사용으로 다양하고 풍부한 색채로 화가들은 색조의 단계적 변화를 무리 없이 표현할 수 있게 되었습니다. 르네상스 미술의 특징인 하모니엔 발란스를 잘 이룬 작품입니다. 신 중심의 사회에서 인간 중심의 사회로 나가고자 하는 바람이 있는 것입니다. 서양미술 혁신의 첫번째로 르네상스 미술 이야기부터 하겠습니다.\n",
      "\n",
      "5 번 문서\n",
      "원문 :  힘은 크기와 방향을 갖는 벡터양으로서 힘의 크기를 나타내는 SI 단위는 뉴턴(N)이다. 1 N은 의 물체에 작용하여 의 가속도 크기로 운동 상태를 변화시키는 힘의 크기다.\n",
      "지구상에서 거시적인 물체의 운동에 영향을 주는 힘에는 우선 지구가 물체를 잡아당기는 지구 중력이 있고, 닿아있는 두 물체 사이에서 접촉면에 수직으로 밀어주는 수직항력과 접촉면에 수평인 방향의 상대적인 운동을 방해하는 마찰력이 있다. 또한 물체가 공기나 물 등 유체 속에서 받는 부력이나 유체 저항, 고무줄이나 스프링 등이 길이가 늘어나거나 줄어들면서 연결되어 있는 물체에 작용하는 탄성력, 길이가 늘어나지 않는 끈처럼 길이 방향으로 잡아당겼을 때 끊어지지 않기 위해 각 부분에 작용하는 장력, 자석이나 전기를 띤 물체 사이에 작용하는 전자기력 등이 있다.\n",
      "현재까지 대부분의 물리학자들은 자연 현상이 네 종류의 기본힘에 의해 지배된다고 보고 있다. 중력(gravitational force), 전자기력(electromagnetic force), 강력(strong force), 약력(weak force)이 그것이다. 중력은 질량이 있는 물체 사이에 작용하는 힘으로서 만유인력이라고도 하며, 앞서 언급한 지구 중력도 기본적으로 만유인력이다. 전자기력은 자석이나 전기를 띤 물체 사이에 작용하는 힘으로 미시적인 원자 구조 및 물질의 구조를 결정한다. 앞서 언급한 수직항력, 마찰력, 부력, 유체 저항, 탄성력, 장력 등은 모두 기본적으로 전자기력으로서, 물체를 이루고 있는 원자들과 원자 안팎의 전자들 사이의 상호작용이다. 강력과 약력은 원자핵 구조 및 원자보다 작은 입자들의 상호작용을 이해하는 데 필요한 힘으로서 입자 사이의 거리가 원자핵 크기보다 짧아야만 유효하게 작용한다.\n",
      "물체에 작용하는 힘이 여러 가지인 경우 알짜힘은 작용하는 모든 힘의 벡터합으로 주어진다. 뉴턴 제이법칙은 물체에 작용하는 알짜힘이 물체 운동량의 시간변화율과 같다는 것이다. 뉴턴 제삼법칙은 작용·반작용 법칙으로서, 힘의 속성이 상호작용이기 때문에 두 물체 사이에 작용하는 힘은 서로 방향이 반대이고 그 크기는 같다는 것이다. 뉴턴이 알고 있던 힘은 모두 작용·반작용 법칙을 따랐지만, 작용·반작용 법칙을 따르지 않는 힘도 존재한다. 예를 들어 수직 방향으로 상대적인 운동을 하는 두 전하 사이의 자기력은 작용·반작용 법칙을 따르지 않는다.\n",
      " \n",
      "요약 :  중력은 질량이 있는 물체 사이에 작용하는 힘으로서 만유인력이라고도 하며, 앞서 언급한 지구 중력도 기본적으로 만유인력이다. 뉴턴 제삼법칙은 작용·반작용 법칙으로서, 힘의 속성이 상호작용이기 때문에 두 물체 사이에 작용하는 힘은 서로 방향이 반대이고 그 크기는 같다는 것이다. 물체에 작용하는 힘이 여러 가지인 경우 알짜힘은 작용하는 모든 힘의 벡터합으로 주어진다. 강력과 약력은 원자핵 구조 및 원자보다 작은 입자들의 상호작용을 이해하는 데 필요한 힘으로서 입자 사이의 거리가 원자핵 크기보다 짧아야만 유효하게 작용한다. 전자기력은 자석이나 전기를 띤 물체 사이에 작용하는 힘으로 미시적인 원자 구조 및 물질의 구조를 결정한다. 앞서 언급한 수직항력, 마찰력, 부력, 유체 저항, 탄성력, 장력 등은 모두 기본적으로 전자기력으로서, 물체를 이루고 있는 원자들과 원자 안팎의 전자들 사이의 상호작용이다. 1 N은 의 물체에 작용하여 의 가속도 크기로 운동 상태를 변화시키는 힘의 크기다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(data)):\n",
    "    print(i+1,'번 문서')\n",
    "    print('원문 : ',data.loc[i].article_text)\n",
    "    print(' ')\n",
    "    print('요약 : ',data.loc[i].summary)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문제 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문장 생성에 쓸 중요 단어 구하기 위한 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['서버(server)컴퓨터란 전용선을 통해 인터넷에 직접 연결되어 있는 컴퓨터를 가리키는데, 24시간 인터넷에 연결되어있고 서버 컴퓨터 접속 주소만 알면 누구나 서버 컴퓨터의 내용을 볼 수 있습니다.',\n",
       " '인터넷 회선을 통해 서버 컴퓨터에 접속하는 사용자 컴퓨터를 클라이언트(client)컴퓨터라고 합니다.',\n",
       " '웹 디자이너나 웹 개발자들은 자신이 제작한 최신 웹사이트를 항상 서버 컴퓨터에 업로드해 놓기 때문에 사용자들은 자신의 위치에 상관없이 어디에서나 인터넷에 접속해서 해당 웹사이트의 내용을 볼 수 있습니다.',\n",
       " \"이것을 '서버 호스팅 서비스' 혹은 '웹 호스팅 서비스'라고 하는데, 개인 웹사이트를 운영하는 사람들은 대부분 이런 호스팅 서비스를 이용합니다.\",\n",
       " '우리는 많은 시간 인터넷을 이용하고 있지만, 이는 인터넷 회선을 통해 인터넷 서비스를 이용하는 것일 뿐, 내 컴퓨터 안의 파일이 인터넷에 연결되어 있는 것은 아닙니다.',\n",
       " '서버 정보를 가져와 보여주는 것은 사용자 컴퓨터 안의 웹 브라우저이기 때문에 좁은 의미로 웹브라우저를 클라이언트라고도 합니다.',\n",
       " '호스팅 서비스는 어떤 서버를 이용하느냐에 따라 윈도우 서버 호스팅과 리눅스 서버 호스팅으로 나뉘는데, 윈도우 서버에서는 ASP나 ASAP.NET 프로그래밍 언어를 사용하고, 리눅스 서버에서는 PHP 프로그래밍 언어를 사용하며 좀 더 대중적이고 저렴합니다.']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['summary_sentences']=data['summary'].apply(sent_tokenize)\n",
    "data['summary_sentences'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [서버, 컴퓨터, 란, 전용선, 을, 통해, 인터넷, 직접, 연결, 되어다, 있다,...\n",
       "1    [귀납, 과거, 사례, 라든지, 축적, 되다, 데이터, 분석, 그, 안, 에서, 보...\n",
       "2    [해당, 영상, 에는, 미국, 전, 대통령, 버락, 오바마, 집무실, 배경, 도널드...\n",
       "3    [사실, 상, 서양, 미술사, 에서, 가장, 획기, 적, 인, 사건, 평면, 위, ...\n",
       "4    [중력, 질량, 있다, 물체, 사이, 작용, 힘, 으로서, 만유인력, 이라고도, 앞...\n",
       "Name: token, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tokenized_data_for_word']=data['summary_sentences'].apply(tokenization)\n",
    "    \n",
    "data['tokenized_data_for_word']=data['tokenized_data_for_word'].apply(preprocess_sentences)\n",
    "\n",
    "def list_to_string(tokenized_data):\n",
    "    tmp=[]\n",
    "    for token_sentence in tokenized_data:\n",
    "        for token in token_sentence:\n",
    "            tmp.append(token)\n",
    "    return tmp\n",
    "\n",
    "data['token']=data['tokenized_data_for_word'].apply(list_to_string)\n",
    "\n",
    "data['token']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### summary 내의 단어들에 대한 점수 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    {0: -2072337172959.853, 1: -1335681052378.5742...\n",
       "1    {0: 1189318012022.2666, 1: 8838910641710.56, 2...\n",
       "2    {0: 621801330570984.2, 1: 1099655828618137.8, ...\n",
       "3    {0: -40475531802869.016, 1: -1449599601450.140...\n",
       "4    {0: -38247218842.43525, 1: -312733097593.92474...\n",
       "Name: word_score, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_word_vector(word):                        \n",
    "    if len(word) != 0:                        \n",
    "        sum=0                        \n",
    "        for token in word:\n",
    "            try: \n",
    "                sum+=kovec.wv[token]\n",
    "            except Exception:\n",
    "                sum+=zero_vector\n",
    "        return sum\n",
    "    else:\n",
    "        return zero_vector\n",
    "\n",
    "def words_to_vectors(words):\n",
    "    return [calculate_word_vector(word) for word in words]\n",
    "\n",
    "data['word_value']=data['token'].apply(words_to_vectors)\n",
    "data['word_value']\n",
    "\n",
    "data['SimMatrix_word']=data['word_value'].apply(similarity_matrix)\n",
    "data['SimMatrix_word']\n",
    "\n",
    "data['word_score']=data['SimMatrix_word'].apply(calculate_score)\n",
    "data['word_score']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranked_words(tokenized_data, scores, n=100):\n",
    "    top_scores=sorted(((scores[i],s)\n",
    "                      for i,s in enumerate(tokenized_data)),\n",
    "                     reverse=True)\n",
    "    #top_n_sentences=[sentence for score,sentence in top_scores[:n]]\n",
    "    top_n_sentences=[]\n",
    "    for score, word in top_scores:\n",
    "        if word not in top_n_sentences:\n",
    "            top_n_sentences.append(word)\n",
    "    return \" \".join(top_n_sentences)\n",
    "\n",
    "data['important_word'] = data.apply(lambda x:\n",
    "                           ranked_words(x.token, x.word_score),axis=1)\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "word_set = data['important_word'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 형태소 분석을 이용한 빈칸뚫기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[responseCode] 200\n",
      "[responBody]\n",
      "월\n",
      "대응\n",
      "대통령\n",
      "일\n",
      "요인\n",
      "유튜브\n",
      "포르노\n",
      "경쟁\n",
      "회로\n",
      "오바마\n",
      "콘텐츠\n",
      "제작\n",
      "실제\n",
      "마이크로소프트\n",
      "트럼프\n",
      "트레이스\n",
      "처벌\n",
      "영상\n",
      "비판\n",
      "페이스북\n",
      "미국\n",
      "버락\n",
      "배경\n",
      "버즈피드\n",
      "생성자\n",
      "연구\n",
      "집무\n",
      "제작\n",
      "배포\n",
      "확장\n",
      "해당\n",
      "알고리즘\n",
      "딥\n",
      "정권\n",
      "경고\n",
      "진짜\n",
      "진행\n",
      "페이크\n",
      "시행\n",
      "국내\n",
      "구글\n",
      "위험\n",
      "발견\n",
      "위\n",
      "법\n",
      "식별\n",
      "도널드\n",
      "개\n",
      "식별\n",
      "필요\n",
      "강화\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import urllib3\n",
    "import json\n",
    "import requests\n",
    "import sys\n",
    "\n",
    "openApiURL = \"http://aiopen.etri.re.kr:8000/WiseNLU\" \n",
    "\n",
    "openApiURL2 = \"http://aiopen.etri.re.kr:8000/WiseNLU_spoken\"\n",
    " \n",
    "accessKey = \"d4a16891-dd45-4883-a873-777a8fda8787\"\n",
    "analysisCode = \"ner\"\n",
    "text = \"\"\n",
    " \n",
    "result=\"\"\n",
    "text += word_set\n",
    "\n",
    "requestJson = {\n",
    "    \"access_key\": accessKey,\n",
    "    \"argument\": {\n",
    "        \"text\": text,\n",
    "        \"analysis_code\": analysisCode\n",
    "    }\n",
    "}\n",
    " \n",
    "http = urllib3.PoolManager()\n",
    "response = http.request(\n",
    "    \"POST\",\n",
    "    openApiURL,\n",
    "    headers={\"Content-Type\": \"application/json; charset=UTF-8\"},\n",
    "    body=json.dumps(requestJson)\n",
    ")\n",
    "\n",
    " \n",
    "print(\"[responseCode] \" + str(response.status))\n",
    "print(\"[responBody]\")\n",
    "\n",
    "\n",
    "data_2 = json.loads(str(response.data,\"utf-8\")) # create json object using string\n",
    "\n",
    "sentence=data_2['return_object']['sentence'] # get the data of sentences\n",
    "\n",
    "for s in sentence: \n",
    "    for w in s['word']: #  for loop : words\n",
    "\n",
    "        text=w['text'] # the text of word\n",
    "\n",
    "        text_id=int(w['id']) # the id of word\n",
    "\n",
    "        begin=int(w['begin']) # the beginning index of morphemes in word\n",
    "\n",
    "        end=int(w['end']) # the ending index of morphemes in word\n",
    "\n",
    "    \n",
    "        for i in range(begin, end+1): # for : morphemes\n",
    "\n",
    "            lemma=s['morp'][i]['lemma'] # morpheme\n",
    "\n",
    "            pos=s['morp'][i]['type'] # tag\n",
    "            ''''sys.stdout.write(\"[\")'''\n",
    "            if pos==\"NNG\":\n",
    "                #sys.stdout.write(\"일반명사\")\n",
    "                sys.stdout.write(lemma+\"\\n\")\n",
    "                result +=lemma+\" \"\n",
    "            if pos==\"NNP\":\n",
    "                #sys.stdout.write(\"고유명사\")\n",
    "                sys.stdout.write(lemma+\"\\n\")\n",
    "                result +=lemma+\" \"\n",
    "'''\n",
    "            if pos==\"NNB\":\n",
    "                sys.stdout.write(\"의존명사\")\n",
    "            if pos==\"NP\":\n",
    "                sys.stdout.write(\"대명사\")\n",
    "            if pos==\"NR\":\n",
    "                sys.stdout.write(\"수사\")\n",
    "            if pos==\"VV\":\n",
    "                sys.stdout.write(\"동사\")\n",
    "            if pos==\"VA\":\n",
    "                sys.stdout.write(\"형용사\")\n",
    "            if pos==\"VX\":\n",
    "                sys.stdout.write(\"보조용언\")\n",
    "            if pos==\"VCP\":\n",
    "                sys.stdout.write(\"긍정지정사\")\n",
    "            if pos==\"VCN\":\n",
    "                sys.stdout.write(\"부정지정사\")\n",
    "            if pos==\"MM\":\n",
    "                sys.stdout.write(\"관형사\")\n",
    "            if pos==\"MAG\":\n",
    "                sys.stdout.write(\"일반부사\")\n",
    "            if pos==\"MAJ\":\n",
    "                sys.stdout.write(\"접속부사\")\n",
    "            if pos==\"IC\":\n",
    "                sys.stdout.write(\"감탄사\")\n",
    "            if pos==\"JKS\":\n",
    "                sys.stdout.write(\"주격조사\")\n",
    "            if pos==\"JKC\":\n",
    "                sys.stdout.write(\"보격조사\")\n",
    "            if pos==\"JKG\":\n",
    "                sys.stdout.write(\"관형격조사\")\n",
    "            if pos==\"JKO\":\n",
    "                sys.stdout.write(\"목적격조사\")\n",
    "            if pos==\"JKB\":\n",
    "                sys.stdout.write(\"부사격조사\")\n",
    "            if pos==\"JKV\":\n",
    "                sys.stdout.write(\"호격조사\")\n",
    "            if pos==\"JKQ\":\n",
    "                sys.stdout.write(\"인용격조사\")\n",
    "            if pos==\"JX\":\n",
    "                sys.stdout.write(\"보격조사\")\n",
    "            if pos==\"JC\":\n",
    "                sys.stdout.write(\"접속조사\")\n",
    "            if pos==\"EP\":\n",
    "                sys.stdout.write(\"선어말어미\")\n",
    "            if pos==\"EF\":\n",
    "                sys.stdout.write(\"종결어미\")\n",
    "            if pos==\"EC\":\n",
    "                sys.stdout.write(\"연결어미\")\n",
    "            if pos==\"ETN\":\n",
    "                sys.stdout.write(\"명사형전성어미\")\n",
    "            if pos==\"ETM\":\n",
    "                sys.stdout.write(\"관형형전성어미\")\n",
    "            if pos==\"XPN\":\n",
    "                sys.stdout.write(\"체언접두사\")\n",
    "            if pos==\"XSN\":\n",
    "                sys.stdout.write(\"명사파생접미사\")\n",
    "            if pos==\"XSV\":\n",
    "                sys.stdout.write(\"동사파생접미사\")\n",
    "            if pos==\"XSA\":\n",
    "                sys.stdout.write(\"형용사파생접미사\")\n",
    "            if pos==\"XR\":\n",
    "                sys.stdout.write(\"어근\")\n",
    "            if pos==\"SF\":\n",
    "                sys.stdout.write(\"마침표,물음표,느낌표\")\n",
    "            if pos==\"SP\":\n",
    "                sys.stdout.write(\"쉼표,가운데점,콜론,빗금\")\n",
    "            if pos==\"SS\":\n",
    "                sys.stdout.write(\"따옴표,괄호표,줄표\")\n",
    "            if pos==\"SE\":\n",
    "                sys.stdout.write(\"줄임표\")\n",
    "            if pos==\"SO\":\n",
    "                sys.stdout.write(\"붙임표\")\n",
    "            if pos==\"SL\":\n",
    "                sys.stdout.write(\"외국어\")\n",
    "            if pos==\"SH\":\n",
    "                sys.stdout.write(\"한자\")\n",
    "            if pos==\"SW\":\n",
    "                sys.stdout.write(\"기타기호\")\n",
    "            if pos==\"NF\":\n",
    "                sys.stdout.write(\"명사추정범주\")\n",
    "            if pos==\"NV\":\n",
    "                sys.stdout.write(\"용언추정범주\")\n",
    "            if pos==\"SN\":\n",
    "                sys.stdout.write(\"숫자\")\n",
    "            if pos==\"NA\":\n",
    "                sys.stdout.write(\"분석불능범주\") \n",
    "            sys.stdout.write(\"]\")    \n",
    "            sys.stdout.write(lemma+\"/\") # print them\n",
    "            \n",
    "            \n",
    "\n",
    "            if i<end: # print + if the morpheme is not the last one\n",
    "\n",
    "                sys.stdout.write(\" + \")\n",
    "\n",
    "        print()\n",
    "\n",
    "    print()\n",
    "    \n",
    "\n",
    "for s in sentence: \n",
    "    t=0\n",
    "    for w in s['NE']: #  for loop : NE\n",
    "\n",
    "        text=w['text']; # the text of word\n",
    "\n",
    "        text_id=int(w['id']); # the id of word\n",
    "\n",
    "        begin=int(w['begin']) # the beginning index of morphemes in word\n",
    "\n",
    "        end=int(w['end']) # the ending index of morphemes in word\n",
    "        \n",
    "    \n",
    "        for i in range(begin, end+1): # for : morphemes\n",
    "            \n",
    "            ga=s['NE'][t]['type']\n",
    "            t+=1\n",
    "            sys.stdout.write(text+\" : \")\n",
    "            \n",
    "            if ga==\"PS_NAME\":\n",
    "                sys.stdout.write(\"사람 이름\")\n",
    "            if ga==\"LC_OTHERS\":\n",
    "                sys.stdout.write(\"기타 장소\")\n",
    "            if ga==\"LCP_COUNTRY\":\n",
    "                sys.stdout.write(\"국가명\")\n",
    "            if ga==\"LCP_PROVINCE\":\n",
    "                sys.stdout.write(\"도, 주 지역명\")\n",
    "            if ga==\"LCP_COUNTY\":\n",
    "                sys.stdout.write(\"세부 행정구역명\")\n",
    "            if ga==\"LCP_CITY\":\n",
    "                sys.stdout.write(\"도시명\")\n",
    "            if ga==\"LCP_CAPITALCITY\":\n",
    "                sys.stdout.write(\"수도명\")\n",
    "            if ga==\"LCG_RIVER\":\n",
    "                sys.stdout.write(\"강\")\n",
    "            if ga==\"LCG_OCEAN\":\n",
    "                sys.stdout.write(\"바다\")\n",
    "            if ga==\"LCG_MOUNTAIN\":\n",
    "                sys.stdout.write(\"산\")\n",
    "            if ga==\"LCG_CONTINENT\":\n",
    "                sys.stdout.write(\"대륙\")\n",
    "            if ga==\"LC_SPACE\":\n",
    "                sys.stdout.write(\"천체 명칭\")\n",
    "            if ga==\"LCG_ISLAND\":\n",
    "                sys.stdout.write(\"섬\")\n",
    "\n",
    "            if ga==\"OG_OTHERS\":\n",
    "                sys.stdout.write(\"기타 기관/단체\")\n",
    "            if ga==\"OGG_ECONOMY\":\n",
    "                sys.stdout.write(\"경제 관련 기관\")\n",
    "            if ga==\"OGG_EDUCATION\":\n",
    "                sys.stdout.write(\"교육 기관\")\n",
    "            if ga==\"OGG_MILITARY\":\n",
    "                sys.stdout.write(\"군사 기관/\")\n",
    "            if ga==\"OGG_MEDIA\":\n",
    "                sys.stdout.write(\"미디어 기관\")\n",
    "            if ga==\"OGG_SPORTS\":\n",
    "                sys.stdout.write(\"스포츠 기관\")\n",
    "            if ga==\"OGG_ART\t\":\n",
    "                sys.stdout.write(\"예술 기관\")\n",
    "            if ga==\"OGG_MEDICINE\":\n",
    "                sys.stdout.write(\"의료 기관\")\n",
    "            if ga==\"OGG_RELIGION\":\n",
    "                sys.stdout.write(\"종교 기관\")\n",
    "            if ga==\"OGG_SCIENCE\":\n",
    "                sys.stdout.write(\"과학 기관\")\n",
    "            if ga==\"OGG_LIBRARY\":\n",
    "                sys.stdout.write(\"도서관\")\n",
    "            if ga==\"OGG_LAW\":\n",
    "                sys.stdout.write(\"법률 기관\")\n",
    "            if ga==\"OGG_POLITICS\":\n",
    "                sys.stdout.write(\"정부/행정 기관\")\n",
    "            if ga==\"OGG_FOOD\":\n",
    "                sys.stdout.write(\"음식 업체\")\n",
    "            if ga==\"OGG_HOTEL\":\n",
    "                sys.stdout.write(\"숙박 업체\")\n",
    "            if ga==\"DT_OTHERS\":\n",
    "                sys.stdout.write(\"기타 날짜\")\n",
    "            if ga==\"DT_DURATION\":\n",
    "                sys.stdout.write(\"기간\")\n",
    "            if ga==\"DT_DAY\":\n",
    "                sys.stdout.write(\"날짜/절기\")\n",
    "            if ga==\"DT_MONTH\":\n",
    "                sys.stdout.write(\"달\")\n",
    "            if ga==\"DT_YEAR\":\n",
    "                sys.stdout.write(\"년\")\n",
    "            if ga==\"DT_SEASON\":\n",
    "                sys.stdout.write(\"계절\")\n",
    "            if ga==\"DT_GEOAGE\":\n",
    "                sys.stdout.write(\"지질시대\")\n",
    "            if ga==\"DT_DYNASTY\":\n",
    "                sys.stdout.write(\"왕조시대\")\n",
    "            if ga==\"TI_OTHERS\":\n",
    "                sys.stdout.write(\"기타 시간\")\n",
    "            if ga==\"TI_DURATION\":\n",
    "                sys.stdout.write(\"기간\")\n",
    "            if ga==\"TI_HOUR\":\n",
    "                sys.stdout.write(\"시각\")\n",
    "            if ga==\"TI_MINUTE\":\n",
    "                sys.stdout.write(\"분\")\n",
    "            if ga==\"TI_SECOND\":\n",
    "                sys.stdout.write(\"초\")\n",
    "            if ga==\"CV_NAME\":\n",
    "                sys.stdout.write(\"문명/문화\")\n",
    "            if ga==\"CV_TRIBE\":\n",
    "                sys.stdout.write(\"민족/종족\")\n",
    "            if ga==\"CV_SPORTS\":\n",
    "                sys.stdout.write(\"스포츠\")\n",
    "            if ga==\"CV_SPORTS_INST\":\n",
    "                sys.stdout.write(\"스포츠 용품\")\n",
    "            if ga==\"CV_POLICY\":\n",
    "                sys.stdout.write(\"제도/정책\")\n",
    "            if ga==\"CV_TAX\":\n",
    "                sys.stdout.write(\"조세\")\n",
    "            if ga==\"CV_FUNDS\":\n",
    "                sys.stdout.write(\"기금\")\n",
    "            if ga==\"CV_LANGUAGE\":\n",
    "                sys.stdout.write(\"언어\")\n",
    "            if ga==\"CV_BUILDING_TYPE\":\n",
    "                sys.stdout.write(\"건축양식\")\n",
    "            if ga==\"CV_FOOD\t\":\n",
    "                sys.stdout.write(\"음식\")\n",
    "            if ga==\"CV_DRINK\":\n",
    "                sys.stdout.write(\"음료수\")\n",
    "            if ga==\"CV_CLOTHING\":\n",
    "                sys.stdout.write(\"의복\")\n",
    "            if ga==\"CV_POSITION\":\n",
    "                sys.stdout.write(\"직위\")\n",
    "            if ga==\"CV_RELATION\":\n",
    "                sys.stdout.write(\"인간 관계\")\n",
    "            if ga==\"CV_OCCUPATION\":\n",
    "                sys.stdout.write(\"직업\")\n",
    "            if ga==\"CV_CURRENCY\":\n",
    "                sys.stdout.write(\"통화\")\n",
    "            if ga==\"CV_PRIZE\":\n",
    "                sys.stdout.write(\"상\")\n",
    "            if ga==\"CV_LAW\":\n",
    "                sys.stdout.write(\"법/법률\")\n",
    "            if ga==\"CV_FOOD_STYLE\":\n",
    "                sys.stdout.write(\"음식 종류\")\n",
    "            if ga==\"AM_OTHERS\":\n",
    "                sys.stdout.write(\"기타 동물\")\n",
    "            if ga==\"AM_INSECT\":\n",
    "                sys.stdout.write(\"곤충\")\n",
    "            if ga==\"AM_BIRD\":\n",
    "                sys.stdout.write(\"조류\")\n",
    "            if ga==\"AM_FISH\":\n",
    "                sys.stdout.write(\"어류\")\n",
    "            if ga==\"AM_MAMMALIA\":\n",
    "                sys.stdout.write(\"포유류\")\n",
    "            if ga==\"AM_AMPHIBIA\":\n",
    "                sys.stdout.write(\"양서류\")\n",
    "            if ga==\"AM_REPTILIA\":\n",
    "                sys.stdout.write(\"파충류\")\n",
    "            if ga==\"AM_TYPE\":\n",
    "                sys.stdout.write(\"동물 분류\")\n",
    "            if ga==\"AM_PART\":\n",
    "                sys.stdout.write(\"신체 부위\")\n",
    "            if ga==\"PT_OTHERS\":\n",
    "                sys.stdout.write(\"기타 식물\")\n",
    "            if ga==\"PT_FRUIT\":\n",
    "                sys.stdout.write(\"과일\")\n",
    "            if ga==\"PT_FLOWER\":\n",
    "                sys.stdout.write(\"꽃\")\n",
    "            if ga==\"PT_TREE\":\n",
    "                sys.stdout.write(\"나무\")\n",
    "            if ga==\"PT_GRASS\":\n",
    "                sys.stdout.write(\"풀\")\n",
    "            if ga==\"PT_TYPE\":\n",
    "                sys.stdout.write(\"식물 유형\")\n",
    "            if ga==\"PT_PART\":\n",
    "                sys.stdout.write(\"식물의 한 부분\")\n",
    "\n",
    "            if ga==\"QT_OTHERS\":\n",
    "                sys.stdout.write(\"기타 수량\")\n",
    "            if ga==\"QT_AGE\":\n",
    "                sys.stdout.write(\"나이\")\n",
    "            if ga==\"QT_SIZE\":\n",
    "                sys.stdout.write(\"크기/넓이\")\n",
    "            if ga==\"QT_LENGTH\":\n",
    "                sys.stdout.write(\"길이/거리/높이\")\n",
    "            if ga==\"QT_COUNT\":\n",
    "                sys.stdout.write(\"개수/빈도\")\n",
    "            if ga==\"QT_MAN_COUNT\":\n",
    "                sys.stdout.write(\"인원수\")\n",
    "            if ga==\"QT_WEIGHT\":\n",
    "                sys.stdout.write(\"무게\")\n",
    "            if ga==\"QT_PERCENTAGE\":\n",
    "                sys.stdout.write(\"비율\")\n",
    "            if ga==\"QT_SPEED\":\n",
    "                sys.stdout.write(\"속도\")\n",
    "            if ga==\"QT_TEMPERATURE\":\n",
    "                sys.stdout.write(\"\")\n",
    "            if ga==\"QT_VOLUME\":\n",
    "                sys.stdout.write(\"부피\")\n",
    "            if ga==\"QT_ORDER\":\n",
    "                sys.stdout.write(\"순서\")\n",
    "            if ga==\"QT_PRICE\":\n",
    "                sys.stdout.write(\"금액\")\n",
    "            if ga==\"QT_PHONE\":\n",
    "                sys.stdout.write(\"전화번호\")\n",
    "            if ga==\"QT_SPORTS\":\n",
    "                sys.stdout.write(\"스포츠 관련 수량\")\n",
    "            if ga==\"QT_CHANNEL\":\n",
    "                sys.stdout.write(\"채널\")\n",
    "            if ga==\"QT_ALBUM\":\n",
    "                sys.stdout.write(\"앨범 관련 수량\")\n",
    "            if ga==\"QT_ZIPCODE\":\n",
    "                sys.stdout.write(\"우편번호\")\n",
    "            if ga==\"FD_OTHERS\":\n",
    "                sys.stdout.write(\"과학 학문\")\n",
    "            if ga==\"FD_SCIENCE\":\n",
    "                sys.stdout.write(\"사회과학 학문\")\n",
    "            if ga==\"FD_SOCIAL_SCIENCE\":\n",
    "                sys.stdout.write(\"정치/경제/사회 학문\")\n",
    "            if ga==\"FD_MEDICINE\":\n",
    "                sys.stdout.write(\"의학 관련 학문\")\n",
    "            if ga==\"FD_ART\":\n",
    "                sys.stdout.write(\"예술관련 학문\")\n",
    "            if ga==\"FD_PHILOSOPHY\":\n",
    "                sys.stdout.write(\"철학 관련 학문\")\n",
    "\n",
    "            if ga==\"TR_OTHERS\":\n",
    "                sys.stdout.write(\"기타이론\")\n",
    "            if ga==\"TR_SCIENCE\":\n",
    "                sys.stdout.write(\"과학 관련 이론\")\n",
    "            if ga==\"TR_SOCIAL_SCIENCE\":\n",
    "                sys.stdout.write(\"사회과학 이론\")\n",
    "            if ga==\"TR_ART\":\n",
    "                sys.stdout.write(\"예술관련 이론\")\n",
    "            if ga==\"TR_PHILOSOPHY\":\n",
    "                sys.stdout.write(\"철학 이론\")\n",
    "            if ga==\"TR_MEDICINE\":\n",
    "                sys.stdout.write(\"의학 진단법\")\n",
    "\n",
    "            if ga==\"EV_OTHERS\":\n",
    "                sys.stdout.write(\"기타 사건\")\n",
    "            if ga==\"EV_ACTIVITY\":\n",
    "                sys.stdout.write(\"사회운동\")\n",
    "            if ga==\"EV_WAR_REVOLUTION\":\n",
    "                sys.stdout.write(\"전쟁/혁명\")\n",
    "            if ga==\"EV_SPORTS\":\n",
    "                sys.stdout.write(\"스포츠/레저\")\n",
    "            if ga==\"EV_FESTIVAL\":\n",
    "                sys.stdout.write(\"축제\")\n",
    "            if ga==\"MT_ELEMENT\":\n",
    "                sys.stdout.write(\"원소명\")\n",
    "            if ga==\"MT_METAL\":\n",
    "                sys.stdout.write(\"금속물\")\n",
    "            if ga==\"MT_ROCK\":\n",
    "                sys.stdout.write(\"암석\")\n",
    "            if ga==\"MT_CHEMICAL\":\n",
    "                sys.stdout.write(\"화학물질\")\n",
    "            if ga==\"TM_COLOR\":\n",
    "                sys.stdout.write(\"색\")\n",
    "            if ga==\"TM_DIRECTION\":\n",
    "                sys.stdout.write(\"방향\")\n",
    "            if ga==\"TM_CLIMATE\":\n",
    "                sys.stdout.write(\"기후지역\")\n",
    "            if ga==\"TM_SHAPE\":\n",
    "                sys.stdout.write(\"모양/형태\")\n",
    "            if ga==\"TM_CELL_TISSUE\":\n",
    "                sys.stdout.write(\"세포/조직/기관\")\n",
    "            if ga==\"TMM_DISEASE\":\n",
    "                sys.stdout.write(\"증세/질병\")\n",
    "            if ga==\"TMM_DRUG\":\n",
    "                sys.stdout.write(\"약/약품명\")\n",
    "            if ga==\"TMI_HW\":\n",
    "                sys.stdout.write(\"IT 하드웨어\")\n",
    "            if ga==\"TMI_SW\":\n",
    "                sys.stdout.write(\"IT 소프트웨어\")\n",
    "            if ga==\"TMI_SITE\":\n",
    "                sys.stdout.write(\"URL 주소\")\n",
    "            if ga==\"TMI_EMAIL\":\n",
    "                sys.stdout.write(\"이메일주소\")\n",
    "            if ga==\"TMI_MODEL\":\n",
    "                sys.stdout.write(\"모델명, 부품류\")\n",
    "            if ga==\"TMI_SERVICE\":\n",
    "                sys.stdout.write(\"IT 서비스\")\n",
    "            if ga==\"TMI_PROJECT\":\n",
    "                sys.stdout.write(\"프로젝트\")\n",
    "            if ga==\"TMIG_GENRE\":\n",
    "                sys.stdout.write(\"게임 장르\")\n",
    "            if ga==\"TM_SPORTS\":\n",
    "                sys.stdout.write(\"스포츠/레저\")\n",
    "            if ga==\"AFW_DOCUMENT\":\n",
    "                sys.stdout.write(\"서적\")\n",
    "            if ga==\"AFW_PERFORMANCE\":\n",
    "                sys.stdout.write(\"가극\")\n",
    "            if ga==\"AFW_VIDEO\":\n",
    "                sys.stdout.write(\"비디오\")\n",
    "            if ga==\"AFW_ART_CRAFT\":\n",
    "                sys.stdout.write(\"미술작품\")\n",
    "            if ga==\"AFW_MUSIC\":\n",
    "                sys.stdout.write(\"음악작품\")\n",
    "            if ga==\"AF_WARES\":\n",
    "                sys.stdout.write(\"상품\")\n",
    "            if ga==\"AF_TRANSPORT\":\n",
    "                sys.stdout.write(\"운송수단\")\n",
    "            if ga==\"AF_WEAPON\":\n",
    "                sys.stdout.write(\"무기\")\n",
    "            if ga==\"AF_MUSICAL_INSTRUMENT\":\n",
    "                sys.stdout.write(\"악기\")\n",
    "            if ga==\"AF_ROAD\":\n",
    "                sys.stdout.write(\"도로\")\n",
    "            if ga==\"AF_BUILDING\":\n",
    "                sys.stdout.write(\"건축물\")\n",
    "            if ga==\"AF_CULTURAL_ASSET\":\n",
    "                sys.stdout.write(\"문화재\")\n",
    "            if ga==\"AF_WORKS\":\n",
    "                sys.stdout.write(\"기타작품\")\n",
    "            if i<end:\n",
    "                break\n",
    "        print()\n",
    "'''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords             #불용어\n",
    "from urllib.request import urlretrieve\n",
    "import zipfile\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import gensim\n",
    "from urllib.request import urlretrieve, urlopen\n",
    "import gzip\n",
    "import zipfile\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import pandas as pd\n",
    "from gensim.test.utils import common_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 위에서 추린 단어들을 사용자가 입력한 텍스트 전반의 키워드 중심으로 중요도 재배열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'gensim.models.word2vec.Word2Vec'>\n",
      "[('처벌', 0.57618254), ('위험', 0.37469196), ('포르노', 0.32359743), ('법', 0.3183799), ('요인', 0.30952168), ('경고', 0.2800363), ('비판', 0.24263857), ('콘텐츠', 0.2322104), ('대응', 0.22861002), ('실제', 0.22842626), ('연구', 0.22263357), ('국내', 0.21246625), ('해당', 0.20864704), ('필요', 0.2000242), ('경쟁', 0.19720986), ('식별', 0.16379878), ('강화', 0.14771946), ('배포', 0.14526124), ('정권', 0.14089127), ('미국', 0.1183561), ('배경', 0.11684337), ('알고리즘', 0.11462056), ('시행', 0.10222533), ('회로', 0.10102601), ('대통령', 0.10026897), ('진짜', 0.098653734), ('영상', 0.09785205), ('개', 0.09257738), ('위', 0.047064636), ('일', 0.0403504), ('집무', 0.039007805), ('진행', 0.027587363), ('확장', 0.027098611), ('버락', 0.013818292), ('유튜브', 0), ('오바마', 0), ('마이크로소프트', 0), ('트레이스', 0), ('페이스북', 0), ('버즈피드', 0), ('생성자', 0), ('페이크', 0), ('구글', 0), ('도널드', 0), ('', 0), ('제작', -0.0003935084), ('딥', -0.014643257), ('트럼프', -0.021699859), ('발견', -0.03129503), ('월', -0.15243451)]\n"
     ]
    }
   ],
   "source": [
    "kovec=Word2Vec.load(\"D:\\ko.bin\")\n",
    "print(type(kovec))\n",
    "#model=Word2Vec(data,sg=1,size=100,window=3,min_count=3,workers=4)\n",
    "#kovec.wv.most_similar(\"르네상스\")\n",
    "arr = result.split(\" \")\n",
    "dict={}\n",
    "\n",
    "for word in arr:\n",
    "    try:\n",
    "        dict[word]=kovec.wv.similarity(\"범죄\",word)\n",
    "    except:\n",
    "        dict[word]=0\n",
    "        \n",
    "import operator\n",
    "sdict= sorted(dict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "print(sdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "blank_arr = []\n",
    "for idx in range(len(sdict)):\n",
    "    blank_arr.append(sdict[idx][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['처벌', '위험', '포르노', '법', '요인', '경고', '비판', '콘텐츠', '대응', '실제', '연구', '국내', '해당', '필요', '경쟁', '식별', '강화', '배포', '정권', '미국', '배경', '알고리즘', '시행', '회로', '대통령', '진짜', '영상', '개', '위', '일', '집무', '진행', '확장', '버락', '유튜브', '오바마', '마이크로소프트', '트레이스', '페이스북', '버즈피드', '생성자', '페이크', '구글', '도널드', '', '제작', '딥', '트럼프', '발견', '월']\n"
     ]
    }
   ],
   "source": [
    "print(blank_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "해당 영상에는 미국 전 대통령 버락 오바마가 집무실 배경으로 도널드 트럼프 정권을 **하고 있는데, 이는 진짜 영상이 아닌 딥페이크 영상이었다.\n",
      "정답: 비판\n",
      "\n",
      "딥트레이스는 2018년 한해 7964개의 딥페이크 **을 발견했다.\n",
      "정답: 영상\n",
      "\n",
      "2018년 4월 미국 콘텐츠 제작사인 버즈피드(BuzzFeed)는 이러한 **성을 경고하고자 딥페이크 영상을 유튜브에 올린 바 있다.\n",
      "정답: 위험\n",
      "\n",
      "GAN 알고리즘은 생성자를 위해 식별자라는 **을 넣었는데, 딥페이크 대응을 위해서는 식별자를 강화하는 연구도 필요하다.\n",
      "정답: 요인\n",
      "\n",
      "GAN 알고리즘에서의 두 ** 경쟁이 실제 사회로까지 확장된 셈이다.\n",
      "정답: 요인\n",
      "\n",
      "이에 따라, 국내에서는 딥페이크 포르노 제작 및 배포를 **하는 법이 25일부터 시행된다.\n",
      "정답: 처벌\n",
      "\n",
      "페이스북, 마이크로소프트, 구글 등이 앞장서 이를 식별하는 **를 진행하고 있다.\n",
      "정답: 연구\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question_arr = []\n",
    "result_arr = []\n",
    "for question in data['summary_sentences'][2]:\n",
    "    for word in blank_arr:\n",
    "        question_tmp = question.replace(word,\"*\"*len(word))\n",
    "        if question_tmp != question:\n",
    "            question_arr.append(question_tmp)\n",
    "            result_arr.append(word)\n",
    "            break\n",
    "\n",
    "for idx in range(len(question_arr)):\n",
    "    print(question_arr[idx]+\"\\n정답: \"+result_arr[idx])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
